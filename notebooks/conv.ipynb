{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Knet-Flux CNN benchmark based on [Flux/model-zoo](https://github.com/FluxML/model-zoo/blob/master/vision/mnist/conv.jl) conv.jl example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m registry at `~/.julia/registries/General`\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m git-repo `https://github.com/JuliaRegistries/General.git`\n",
      "\u001b[?25l\u001b[2K\u001b[?25h"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: Some registries failed to update:\n",
      "│     — /home/gridsan/dyuret/.julia/registries/General — failed to fetch from repo\n",
      "└ @ Pkg.API /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.0/Pkg/src/API.jl:157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m    Status\u001b[22m\u001b[39m `~/Klutz.jl/Project.toml`\n",
      " \u001b[90m [3a865a2d]\u001b[39m\u001b[37m CuArrays v0.8.1\u001b[39m\n",
      " \u001b[90m [587475ba]\u001b[39m\u001b[37m Flux v0.6.8\u001b[39m\n",
      " \u001b[90m [1902f260]\u001b[39m\u001b[37m Knet v1.1.1\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "]activate ..; instantiate; st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment this to get Knet profiling info at the end:\n",
    "# ENV[\"KNET_TIMER\"] = ENV[\"AUTOGRAD_TIMER\"] = \"true\"\n",
    "# using Pkg; Pkg.build(\"AutoGrad\"); Pkg.build(\"Knet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Flux, Flux.Data.MNIST, Statistics\n",
    "using Flux: onehotbatch, onecold, crossentropy, throttle\n",
    "using Base.Iterators: repeated, partition\n",
    "using CuArrays\n",
    "using Knet: Knet, AutoGrad, conv4, pool, KnetArray\n",
    "Knet.gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement Chain, Conv and Dense in Knet\n",
    "struct kChain; layers; kChain(ls::Tuple)=new(ls); end\n",
    "kChain(ls...)=kChain(ls)\n",
    "(c::kChain)(x) = (for l in c.layers; x = l(x); end; x)\n",
    "struct kDense; w; b; f; end\n",
    "kDense(nx::Int,ny::Int,fn=identity)=kDense(Knet.param(ny,nx),Knet.param0(ny),fn)\n",
    "(d::kDense)(x) = d.f.(d.w * Knet.mat(x) .+ d.b)\n",
    "struct kConv; w; b; f; end\n",
    "kConv(w1,w2,cx,cy,fn=identity)=kConv(Knet.param(w1,w2,cx,cy),Knet.param0(1,1,cy,1), fn)\n",
    "(f::kConv)(x) = pool(f.f.(conv4(f.w,x) .+ f.b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"28×28×1×1000 CuArray{Float32,4}\", \"10×1000 Flux.OneHotMatrix{CuArray{Flux.OneHotVector,1}}\", \"28×28×1×1000 KnetArray{Float32,4}\", \"1000-element Array{Int64,1}\")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "imgs = MNIST.images()\n",
    "labels = onehotbatch(MNIST.labels(), 0:9)\n",
    "train = [(cat(float.(imgs[i])..., dims = 4), labels[:,i])\n",
    "         for i in partition(1:60_000, 1000)]\n",
    "train = gpu.(train)\n",
    "klabels = MNIST.labels() .+ 1\n",
    "ktrain = [(KnetArray{Float32}(cat(float.(imgs[i])..., dims = 4)), klabels[i])\n",
    "          for i in partition(1:60_000, 1000)]\n",
    "summary.((train[1]..., ktrain[1]...))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(loss(X, Y), accuracy(X, Y)) = (2.302674f0 (tracked), 0.109)\n",
      "  9.770545 seconds (2.27 M allocations: 138.747 MiB, 26.75% gc time)\n",
      "(loss(X, Y), accuracy(X, Y)) = (0.19522423f0 (tracked), 0.942)\n"
     ]
    }
   ],
   "source": [
    "# Run this several times to get timing for Flux:\n",
    "# (loss(X, Y), accuracy(X, Y)) = (2.302674f0 (tracked), 0.109)\n",
    "#   9.770545 seconds (2.27 M allocations: 138.747 MiB, 26.75% gc time)\n",
    "# (loss(X, Y), accuracy(X, Y)) = (0.19522423f0 (tracked), 0.942)\n",
    "\n",
    "m = Chain(\n",
    "  Conv((2,2), 1=>16, relu),\n",
    "  x -> maxpool(x, (2,2)),\n",
    "  Conv((2,2), 16=>8, relu),\n",
    "  x -> maxpool(x, (2,2)),\n",
    "  x -> reshape(x, :, size(x, 4)),\n",
    "  Dense(288, 10), softmax) |> gpu\n",
    "\n",
    "loss(x, y) = crossentropy(m(x), y)\n",
    "accuracy(x, y) = mean(onecold(m(x)) .== onecold(y))\n",
    "opt = ADAM(params(m))\n",
    "\n",
    "X,Y = train[1]\n",
    "@show loss(X, Y), accuracy(X, Y)\n",
    "@time for i in 1:10; Flux.train!(loss, train, opt); end\n",
    "@show loss(X, Y), accuracy(X, Y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Knet.nll(km, kX, kY), Knet.accuracy(km, kX, kY)) = (2.2925608f0, 0.145)\n",
      "  2.766763 seconds (1.58 M allocations: 58.009 MiB, 12.79% gc time)\n",
      "(Knet.nll(km, kX, kY), Knet.accuracy(km, kX, kY)) = (0.15760595f0, 0.951)\n"
     ]
    }
   ],
   "source": [
    "# Run this several times to get timing for Knet:\n",
    "# (Knet.nll(km, kX, kY), Knet.accuracy(km, kX, kY)) = (2.2925608f0, 0.145)\n",
    "#   2.766763 seconds (1.58 M allocations: 58.009 MiB, 12.79% gc time)\n",
    "# (Knet.nll(km, kX, kY), Knet.accuracy(km, kX, kY)) = (0.15760595f0, 0.951)\n",
    "\n",
    "km = kChain(\n",
    "    kConv(2,2,1,16,Knet.relu),\n",
    "    kConv(2,2,16,8,Knet.relu),\n",
    "    kDense(288,10))\n",
    "kX,kY = ktrain[1]\n",
    "iters(n)=(J->((n-=1)>=0))\n",
    "@show Knet.nll(km,kX,kY), Knet.accuracy(km,kX,kY)\n",
    "@time for i in 1:10; Knet.train!(km, ktrain; optimizer=Knet.Adam(), callback=iters(length(ktrain))); end\n",
    "@show Knet.nll(km,kX,kY), Knet.accuracy(km,kX,kY);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CPU tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"28×28×1×1000 Array{Float64,4}\", \"10×1000 Flux.OneHotMatrix{Array{Flux.OneHotVector,1}}\", \"28×28×1×1000 Array{Float64,4}\", \"1000-element Array{Int64,1}\")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "imgs = MNIST.images()\n",
    "labels = onehotbatch(MNIST.labels(), 0:9)\n",
    "train = [(cat(float.(imgs[i])..., dims = 4), labels[:,i])\n",
    "         for i in partition(1:60_000, 1000)]\n",
    "# train = gpu.(train)\n",
    "klabels = MNIST.labels() .+ 1\n",
    "ktrain = [(cat(float.(imgs[i])..., dims = 4), klabels[i])\n",
    "          for i in partition(1:60_000, 1000)]\n",
    "summary.((train[1]..., ktrain[1]...))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(loss(X, Y), accuracy(X, Y)) = (2.302547213644201 (tracked), 0.098)\n",
      " 67.319825 seconds (180.23 M allocations: 55.193 GiB, 42.92% gc time)\n",
      "(loss(X, Y), accuracy(X, Y)) = (1.7696594578438087 (tracked), 0.669)\n"
     ]
    }
   ],
   "source": [
    "# Run this several times to get timing for Flux:\n",
    "\n",
    "m = Chain(\n",
    "  Conv((2,2), 1=>16, relu),\n",
    "  x -> maxpool(x, (2,2)),\n",
    "  Conv((2,2), 16=>8, relu),\n",
    "  x -> maxpool(x, (2,2)),\n",
    "  x -> reshape(x, :, size(x, 4)),\n",
    "  Dense(288, 10), softmax)\n",
    "m0 = deepcopy(m)\n",
    "loss(x, y) = crossentropy(m(x), y)\n",
    "accuracy(x, y) = mean(onecold(m(x)) .== onecold(y))\n",
    "opt = ADAM(params(m))\n",
    "\n",
    "X,Y = train[1]\n",
    "@show loss(X, Y), accuracy(X, Y)\n",
    "@time Flux.train!(loss, train, opt)\n",
    "@show loss(X, Y), accuracy(X, Y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Knet.nll(km, kX, kY), Knet.accuracy(km, kX, kY)) = (2.3025472136442007, 0.098)\n",
      "176.934181 seconds (100.80 k allocations: 31.919 GiB, 17.78% gc time)\n",
      "(Knet.nll(km, kX, kY), Knet.accuracy(km, kX, kY)) = (1.7539083972962197, 0.63)\n"
     ]
    }
   ],
   "source": [
    "# Run this several times to get timing for Knet:\n",
    "f2k(a)=Knet.Param(Array(a))\n",
    "km = kChain(kConv(f2k(m0.layers[1].weight.data),f2k(reshape(m0.layers[1].bias.data,(1,1,16,1))),Knet.relu), \n",
    "            kConv(f2k(m0.layers[3].weight.data),f2k(reshape(m0.layers[3].bias.data,(1,1,8,1))),Knet.relu),\n",
    "            kDense(f2k(m0.layers[6].W.data),f2k(m0.layers[6].b.data),identity))\n",
    "kX,kY = ktrain[1]\n",
    "iters(n)=(J->((n-=1)>=0))\n",
    "@show Knet.nll(km,kX,kY), Knet.accuracy(km,kX,kY)\n",
    "@time Knet.train!(km, ktrain; optimizer=Knet.Adam(), callback=iters(length(ktrain)))\n",
    "@show Knet.nll(km,kX,kY), Knet.accuracy(km,kX,kY);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.0.1",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
