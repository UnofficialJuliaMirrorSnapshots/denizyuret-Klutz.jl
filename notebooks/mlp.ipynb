{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Knet-Flux mlp benchmark based on [Flux/model-zoo](https://github.com/FluxML/model-zoo/blob/master/vision/mnist/mlp.jl) mlp example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m registry at `~/.julia/registries/General`\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m git-repo `https://github.com/JuliaRegistries/General.git`\n",
      "\u001b[?25l\u001b[2K\u001b[?25h"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: Some registries failed to update:\n",
      "│     — /home/gridsan/dyuret/.julia/registries/General — failed to fetch from repo\n",
      "└ @ Pkg.API /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.0/Pkg/src/API.jl:157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m    Status\u001b[22m\u001b[39m `~/Klutz.jl/Project.toml`\n",
      " \u001b[90m [3a865a2d]\u001b[39m\u001b[37m CuArrays v0.8.1\u001b[39m\n",
      " \u001b[90m [587475ba]\u001b[39m\u001b[37m Flux v0.6.8\u001b[39m\n",
      " \u001b[90m [1902f260]\u001b[39m\u001b[37m Knet v1.1.1\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "]activate ..; instantiate; st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment this to get Knet profiling info at the end:\n",
    "# ENV[\"KNET_TIMER\"] = ENV[\"AUTOGRAD_TIMER\"] = \"true\"\n",
    "# using Pkg; Pkg.build(\"AutoGrad\"); Pkg.build(\"Knet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Recompiling stale cache file /home/gridsan/dyuret/.julia/compiled/v1.0/Knet/f4vSz.ji for Knet [1902f260-5fb4-5aff-8c31-6271790ab950]\n",
      "└ @ Base loading.jl:1187\n",
      "WARNING: Method definition gcnode(AutoGrad.Node) in module AutoGrad at /home/gridsan/dyuret/.julia/packages/AutoGrad/eAmjh/src/core.jl:38 overwritten in module Knet at /home/gridsan/dyuret/.julia/packages/Knet/3lzCR/src/gcnode.jl:18.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Flux, Flux.Data.MNIST, Statistics\n",
    "using Flux: onehotbatch, onecold, crossentropy, throttle\n",
    "using Base.Iterators: repeated\n",
    "using CuArrays\n",
    "using Knet: Knet, KnetArray, param, param0, nll, Param, AutoGrad\n",
    "Knet.gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement Chain and Dense in Knet\n",
    "struct kChain; layers; kChain(ls::Tuple)=new(ls); end\n",
    "kChain(ls...)=kChain(ls)\n",
    "(c::kChain)(x) = (for l in c.layers; x = l(x); end; x)\n",
    "struct kDense; w; b; f; end\n",
    "kDense(nx::Int,ny::Int,fn=identity)=kDense(param(ny,nx),param0(ny),fn)\n",
    "(d::kDense)(x) = d.f.(d.w * x .+ d.b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"784×60000 CuArray{Float32,2}\", \"10×60000 Flux.OneHotMatrix{CuArray{Flux.OneHotVector,1}}\", \"784×60000 KnetArray{Float32,2}\", \"60000-element Array{Int64,1}\")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "imgs = MNIST.images()\n",
    "X = hcat(float.(reshape.(imgs, :))...) |> gpu\n",
    "labels = MNIST.labels()\n",
    "Y = onehotbatch(labels, 0:9) |> gpu\n",
    "dataset = repeated((X, Y), 200)\n",
    "\n",
    "kX = KnetArray(Array(X))\n",
    "kY = labels .+ 1\n",
    "kdata = repeated((kX,kY),200)\n",
    "\n",
    "summary.((X,Y,kX,kY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(loss(X, Y), accuracy(X, Y)) = (2.3488135f0 (tracked), 0.11515)\n",
      "  2.402374 seconds (513.62 k allocations: 20.364 MiB, 25.76% gc time)\n",
      "(loss(X, Y), accuracy(X, Y)) = (0.27673373f0 (tracked), 0.9230833333333334)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.27673373f0 (tracked), 0.9230833333333334)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run this several times to get timing for Flux:\n",
    "# (loss(X, Y), accuracy(X, Y)) = (2.2691698f0 (tracked), 0.17285)\n",
    "#  2.402374 seconds (513.62 k allocations: 20.364 MiB, 25.76% gc time)\n",
    "# (loss(X, Y), accuracy(X, Y)) = (0.27879566f0 (tracked), 0.9224166666666667)\n",
    "m = Chain(Dense(28^2, 32, relu),Dense(32, 10),softmax) |> gpu\n",
    "opt = ADAM(params(m))\n",
    "loss(x, y) = crossentropy(m(x), y)\n",
    "accuracy(x, y) = mean(onecold(m(x)) .== onecold(y))\n",
    "@show loss(X, Y), accuracy(X, Y)\n",
    "@time Flux.train!(loss, dataset, opt)\n",
    "@show loss(X, Y), accuracy(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Knet.nll(km, kX, kY), Knet.accuracy(km, kX, kY)) = (2.2998385f0, 0.1048)\n",
      "  0.581472 seconds (360.04 k allocations: 240.723 MiB, 5.80% gc time)\n",
      "(Knet.nll(km, kX, kY), Knet.accuracy(km, kX, kY)) = (0.2898485f0, 0.9210333333333334)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.2898485f0, 0.9210333333333334)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run this several times to get timing for Knet:\n",
    "# (Knet.nll(km, kX, kY), Knet.accuracy(km, kX, kY)) = (2.3258605f0, 0.0694)\n",
    "#   0.581472 seconds (360.04 k allocations: 240.723 MiB, 5.80% gc time)\n",
    "# (Knet.nll(km, kX, kY), Knet.accuracy(km, kX, kY)) = (0.29319283f0, 0.9203833333333333)\n",
    "km = kChain(kDense(28^2, 32, Knet.relu),kDense(32, 10))\n",
    "iters(n)=(J->((n-=1)>=0))\n",
    "@show Knet.nll(km,kX,kY), Knet.accuracy(km,kX,kY)\n",
    "@time Knet.train!(km,kdata,callback=iters(200),optimizer=Knet.Adam())\n",
    "@show Knet.nll(km,kX,kY), Knet.accuracy(km,kX,kY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Knet GPU Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.894881 seconds (347.96 k allocations: 239.375 MiB, 2.89% gc time)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       " \u001b[1m──────────────────────────────────────────────────────────────────────────────────────\u001b[22m\n",
       " \u001b[1m                                      \u001b[22m        Time                   Allocations      \n",
       "                                       ──────────────────────   ───────────────────────\n",
       "           Tot / % measured:                907ms / 73.0%            240MiB / 59.3%    \n",
       "\n",
       " Section                       ncalls     time   %tot     avg     alloc   %tot      avg\n",
       " ──────────────────────────────────────────────────────────────────────────────────────\n",
       " *[1]                             402    158ms  23.8%   393μs    283KiB  0.19%        -\n",
       "   Knet.A_mul_Bt                  201   36.0ms  5.44%   179μs    104KiB  0.07%        -\n",
       " *                                402    113ms  17.0%   281μs    208KiB  0.14%        -\n",
       " +.[2]                            402   74.1ms  11.2%   184μs    302KiB  0.21%        -\n",
       " Knet.cudnnSoftmaxForward         201   55.7ms  8.41%   277μs    219KiB  0.15%  1.09KiB\n",
       " getindex                         201   54.6ms  8.24%   272μs   92.4MiB  64.9%   471KiB\n",
       " sum_outgrads                   3.22k   51.0ms  7.70%  15.9μs   46.3MiB  32.5%  14.7KiB\n",
       " Knet.cudnnSoftmaxForward[1]      201   44.8ms  6.77%   223μs    295KiB  0.20%  1.47KiB\n",
       " record                         2.61k   20.1ms  3.03%  7.68μs   1.56MiB  1.10%        -\n",
       " +.                               402   17.9ms  2.70%  44.4μs    252KiB  0.17%        -\n",
       " *[2]                             201   15.5ms  2.35%  77.3μs    170KiB  0.12%        -\n",
       "   Knet.At_mul_B                  201   12.4ms  1.87%  61.6μs    101KiB  0.07%        -\n",
       " Knet.relu.[1]                    201   15.4ms  2.32%  76.4μs    130KiB  0.09%        -\n",
       "   Knet.reluback.                 201   11.5ms  1.73%  57.1μs   60.5KiB  0.04%        -\n",
       " Knet.relu.                       201   9.36ms  1.41%  46.6μs   54.2KiB  0.04%        -\n",
       " sum[1]                           201   9.19ms  1.39%  45.7μs    124KiB  0.09%        -\n",
       " sum                              201   7.52ms  1.14%  37.4μs   13.4KiB  0.01%        -\n",
       " reshape[1]                       402   3.19ms  0.48%  7.94μs   40.8KiB  0.03%        -\n",
       " +.[1]                            402   2.57ms  0.39%  6.40μs   12.6KiB  0.01%        -\n",
       " reshape                          402   2.20ms  0.33%  5.46μs   28.3KiB  0.02%        -\n",
       " getindex[1]                      201   1.66ms  0.25%  8.25μs   15.7KiB  0.01%        -\n",
       " -[1]                             201   1.50ms  0.23%  7.47μs   12.6KiB  0.01%        -\n",
       " *.[1]                            201   1.26ms  0.19%  6.29μs   15.7KiB  0.01%        -\n",
       " *.                               201   1.24ms  0.19%  6.16μs   15.7KiB  0.01%        -\n",
       " identity.[1]                     201   1.23ms  0.19%  6.12μs   6.28KiB  0.00%        -\n",
       " identity.                        201    851μs  0.13%  4.23μs         -  0.00%        -\n",
       " -                                201    735μs  0.11%  3.66μs   6.28KiB  0.00%        -\n",
       " \u001b[1m──────────────────────────────────────────────────────────────────────────────────────\u001b[22m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       " \u001b[1m────────────────────────────────────────────────────────────────────────────────────────\u001b[22m\n",
       " \u001b[1m                                        \u001b[22m        Time                   Allocations      \n",
       "                                         ──────────────────────   ───────────────────────\n",
       "            Tot / % measured:                 909ms / 69.2%            240MiB / 0.59%    \n",
       "\n",
       " Section                         ncalls     time   %tot     avg     alloc   %tot      avg\n",
       " ────────────────────────────────────────────────────────────────────────────────────────\n",
       " cublasSgemm_v2                   1.00k    271ms  43.0%   269μs    126KiB  8.62%        -\n",
       " sum_32_21                          402   66.9ms  10.6%   166μs   25.1KiB  1.72%        -\n",
       " cudnnSoftmaxForward                201   53.6ms  8.53%   267μs    171KiB  11.7%        -\n",
       "   cudnnCreateTensorDescriptor      402   1.55ms  0.25%  3.86μs         -  0.00%        -\n",
       "   cudnnSetTensorNdDescriptor       402   1.29ms  0.20%  3.21μs         -  0.00%        -\n",
       " cudnnSoftmaxBackward               201   42.2ms  6.71%   210μs    228KiB  15.6%  1.13KiB\n",
       "   cudnnCreateTensorDescriptor      603   2.31ms  0.37%  3.83μs         -  0.00%        -\n",
       "   cudnnSetTensorNdDescriptor       603   1.91ms  0.30%  3.17μs         -  0.00%        -\n",
       " cublasSaxpy_v2                   2.40k   30.8ms  4.89%  12.8μs    225KiB  15.4%        -\n",
       " cudaMemcpy                         607   29.3ms  4.65%  48.2μs   50.5KiB  3.46%        -\n",
       " mul_32_01                        1.80k   21.6ms  3.43%  12.0μs    113KiB  7.72%        -\n",
       " cublasSscal_v2                   1.60k   20.2ms  3.21%  12.6μs    100KiB  6.86%        -\n",
       " add_32_12                          402   12.8ms  2.04%  31.9μs   37.7KiB  2.58%        -\n",
       " mul_32_11                          800   10.1ms  1.60%  12.6μs   75.0KiB  5.14%        -\n",
       " div_32_11                          800   9.81ms  1.56%  12.3μs   75.0KiB  5.14%        -\n",
       " sqrt_32                            800   9.77ms  1.55%  12.2μs   50.0KiB  3.43%        -\n",
       " reluback_32_11                     201   9.72ms  1.54%  48.4μs   18.8KiB  1.29%        -\n",
       " add_32_01                          800   9.61ms  1.53%  12.0μs   50.0KiB  3.43%        -\n",
       " relu_32                            201   7.71ms  1.22%  38.3μs   12.6KiB  0.86%        -\n",
       " sum_32_20                          201   6.59ms  1.05%  32.8μs   6.28KiB  0.43%        -\n",
       " fill_32                            209   3.78ms  0.60%  18.1μs   13.1KiB  0.90%        -\n",
       " getents_32                         201   3.58ms  0.57%  17.8μs   18.8KiB  1.29%        -\n",
       " cudnnDestroyTensorDescriptor     1.00k   3.47ms  0.55%  3.46μs   31.4KiB  2.15%        -\n",
       " one_32                             201   3.35ms  0.53%  16.7μs   12.6KiB  0.86%        -\n",
       " addents_32                         201   3.29ms  0.52%  16.4μs   18.8KiB  1.29%        -\n",
       " cudaMalloc                          12    406μs  0.06%  33.9μs         -  0.00%        -\n",
       " \u001b[1m────────────────────────────────────────────────────────────────────────────────────────\u001b[22m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using TimerOutputs: reset_timer!\n",
    "reset_timer!(Knet.to); reset_timer!(AutoGrad.to)\n",
    "km = kChain(kDense(28^2, 32, Knet.relu),kDense(32, 10))\n",
    "@time Knet.train!(km,kdata,callback=iters(200),optimizer=Knet.Adam())\n",
    "println(); flush(stdout)\n",
    "display(AutoGrad.to)\n",
    "println(); flush(stdout)\n",
    "display(Knet.to)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CPU tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"784×60000 Array{Float64,2}\", \"10×60000 Flux.OneHotMatrix{Array{Flux.OneHotVector,1}}\", \"784×60000 Array{Float64,2}\", \"60000-element Array{Int64,1}\")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "epochs = 10\n",
    "imgs = MNIST.images()\n",
    "X = hcat(float.(reshape.(imgs, :))...) # Float64\n",
    "labels = MNIST.labels()\n",
    "Y = onehotbatch(labels, 0:9)\n",
    "dataset = repeated((X, Y), epochs)\n",
    "\n",
    "kX = X\n",
    "kY = labels .+ 1\n",
    "kdata = repeated((kX,kY), epochs)\n",
    "\n",
    "summary.((X,Y,kX,kY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(loss(X, Y), accuracy(X, Y)) = (2.3871476663323263 (tracked), 0.08006666666666666)\n",
      "  8.411364 seconds (6.07 k allocations: 4.812 GiB, 30.91% gc time)\n",
      "(loss(X, Y), accuracy(X, Y)) = (1.8506316291000398 (tracked), 0.5061166666666667)\n"
     ]
    }
   ],
   "source": [
    "# Run this several times to get CPU timing for Flux:\n",
    "# (loss(X, Y), accuracy(X, Y)) = (2.3871476663323263 (tracked), 0.08006666666666666)\n",
    "#  8.411364 seconds (6.07 k allocations: 4.812 GiB, 30.91% gc time)\n",
    "# (loss(X, Y), accuracy(X, Y)) = (1.8506316291000398 (tracked), 0.5061166666666667)\n",
    "m = Chain(Dense(28^2, 32, relu),Dense(32, 10),softmax) # gpu default is Float32 but cpu default is Float64!!!\n",
    "m0 = deepcopy(m)\n",
    "opt = ADAM(params(m))\n",
    "loss(x, y) = crossentropy(m(x), y)\n",
    "accuracy(x, y) = mean(onecold(m(x)) .== onecold(y))\n",
    "@show loss(X, Y), accuracy(X, Y)\n",
    "@time Flux.train!(loss, dataset, opt)\n",
    "@show loss(X, Y), accuracy(X, Y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Knet.nll(km, kX, kY), Knet.accuracy(km, kX, kY)) = (2.3871476663323263, 0.08006666666666666)\n",
      "  3.668864 seconds (67.47 k allocations: 1.321 GiB, 53.07% gc time)\n",
      "(Knet.nll(km, kX, kY), Knet.accuracy(km, kX, kY)) = (1.8487510324791598, 0.5076166666666667)\n"
     ]
    }
   ],
   "source": [
    "# Run this several times to get CPU timing for Knet:\n",
    "# (Knet.nll(km, kX, kY), Knet.accuracy(km, kX, kY)) = (2.3871476663323263, 0.08006666666666666)\n",
    "#   3.668864 seconds (67.47 k allocations: 1.321 GiB, 53.07% gc time)\n",
    "# (Knet.nll(km, kX, kY), Knet.accuracy(km, kX, kY)) = (1.8487510324791598, 0.5076166666666667)\n",
    "f2k(a)=Param(Array(a))\n",
    "km = kChain(kDense(f2k(m0.layers[1].W.data),f2k(m0.layers[1].b.data),Knet.relu), \n",
    "            kDense(f2k(m0.layers[2].W.data),f2k(m0.layers[2].b.data),identity))\n",
    "iters(n)=(J->((n-=1)>=0))\n",
    "@show Knet.nll(km,kX,kY), Knet.accuracy(km,kX,kY)\n",
    "@time Knet.train!(km,kdata,callback=iters(epochs),optimizer=Knet.Adam())\n",
    "@show Knet.nll(km,kX,kY), Knet.accuracy(km,kX,kY);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "#5 (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can use this to start Knet with exact same model on gpu\n",
    "# m0 = deepcopy(m)\n",
    "# c2k(a)=Param(KnetArray(Array(a)))\n",
    "# km = kChain(kDense(c2k(m0.layers[1].W.data),c2k(m0.layers[1].b.data),Knet.relu), \n",
    "#             kDense(c2k(m0.layers[2].W.data),c2k(m0.layers[2].b.data),identity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.0.1",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
